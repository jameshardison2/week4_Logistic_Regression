{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cf37e0",
   "metadata": {},
   "source": [
    "# Week 4 Notebook  Logistic Regression and Feature Scaling\n",
    "\n",
    "**Author**: James N. Hardison II\n",
    "\n",
    "**Date**: 2025-09-25\n",
    "\n",
    "**Course**: DX799 O1 Data Science Capstone  Mod C  Semester 1\n",
    "\n",
    "**Goal**: Apply logistic regression with proper feature scaling to the Integrated Capstone Project dataset. Demonstrate overfitting control, metric selection, and hyperparameter tuning. This notebook mirrors the structure you used in Week 2 for continuity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacc1b4",
   "metadata": {},
   "source": [
    "> Note  Imported cues from Week 2 headers for consistent structure:  \n",
    "- # Week 2 — Linear Regression with Regularization (CKD)\n",
    "- ## 0) Setup\n",
    "- ## Dataset Choice\n",
    "- ## 1) Load data and normalize column names\n",
    "- ## 2) Target = hemoglobin → numeric + align X/y\n",
    "- ## 3) Preprocess pipeline (impute + encode)\n",
    "- ## 4) Train/Test split\n",
    "- ## 5) Baseline OLS\n",
    "- ## 6) Ridge / 7) Lasso / 8) Elastic Net\n",
    "- ## 9) Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1e5ae",
   "metadata": {},
   "source": [
    "## 1 Project Context\n",
    "\n",
    "State the project in two or three sentences. Mention the outcome to predict as a binary variable. \n",
    "Example  Predict kidney disease progression within a fixed horizon yes or no.\n",
    "\n",
    "Briefly note the client or stakeholder perspective and why this prediction is useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9195d60",
   "metadata": {},
   "source": [
    "## 2 Data Loading and Setup\n",
    "\n",
    "Datasets available in your workspace  \n",
    "- `ckd_dataset_v2.csv`  \n",
    "- `acute_kidney_injury.csv`  \n",
    "- `Diabetic_Nephropathy_v1.xlsx`\n",
    "\n",
    "If you prefer a single dataset, set `USE_COMBINED = False` and provide the path you want. \n",
    "Otherwise, the helper will try a simple union by shared columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay, DetCurveDisplay,\n",
    "                             ConfusionMatrixDisplay, classification_report, auc, roc_curve, precision_recall_curve)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Versions  numpy=\", np.__version__, \"pandas=\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "USE_COMBINED = True  # if False, set SINGLE_DATASET_PATH below\n",
    "SINGLE_DATASET_PATH = \"/mnt/data/ckd_dataset_v2.csv\"  # ignored if USE_COMBINED is True\n",
    "\n",
    "# Attempt to load provided datasets\n",
    "paths = {\n",
    "    'ckd': \"/mnt/data/ckd_dataset_v2.csv\",\n",
    "    'aki': \"/mnt/data/acute_kidney_injury.csv\",\n",
    "    'dn' : \"/mnt/data/Diabetic_Nephropathy_v1.xlsx\",\n",
    "}\n",
    "\n",
    "dfs = {}\n",
    "for k, p in paths.items():\n",
    "    if os.path.exists(p):\n",
    "        try:\n",
    "            if p.endswith('.csv'):\n",
    "                dfs[k] = pd.read_csv(p)\n",
    "            elif p.endswith('.xlsx') or p.endswith('.xls'):\n",
    "                dfs[k] = pd.read_excel(p)\n",
    "            else:\n",
    "                print(f\"Skipping unknown format  {p}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {p}  {e}\")\n",
    "    else:\n",
    "        print(f\"Not found  {p}\")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name} shape  {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1084cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light cleaning  standardize column names\n",
    "def clean_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
    "    return df\n",
    "\n",
    "dfs = {k  clean_cols(v) for k, v in dfs.items()}\n",
    "\n",
    "# Combine by shared columns if requested\n",
    "if USE_COMBINED and len(dfs) > 0:\n",
    "    shared_cols = None\n",
    "    for df in dfs.values():\n",
    "        shared_cols = set(df.columns) if shared_cols is None else shared_cols.intersection(df.columns)\n",
    "    shared_cols = list(shared_cols) if shared_cols else None\n",
    "    if shared_cols and len(shared_cols) >= 5:\n",
    "        combined = pd.concat([df[shared_cols] for df in dfs.values()], ignore_index=True)\n",
    "        data = combined\n",
    "        source = \"combined shared columns\"\n",
    "    else:\n",
    "        # fallback  take the largest df\n",
    "        largest_key = max(dfs, key=lambda k  dfs[k].shape[0])\n",
    "        data = dfs[largest_key]\n",
    "        source = f\"largest dataset  {largest_key}\"\n",
    "else:\n",
    "    if os.path.exists(SINGLE_DATASET_PATH):\n",
    "        if SINGLE_DATASET_PATH.endswith('.csv'):\n",
    "            data = pd.read_csv(SINGLE_DATASET_PATH)\n",
    "        else:\n",
    "            data = pd.read_excel(SINGLE_DATASET_PATH)\n",
    "        data = clean_cols(data)\n",
    "        source = \"single dataset path\"\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No dataset found. Please set SINGLE_DATASET_PATH correctly or upload a dataset.\")\n",
    "\n",
    "print(\"Active data source \", source, \" shape \", data.shape)\n",
    "display(data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b850f",
   "metadata": {},
   "source": [
    "### 2.1 Target Selection\n",
    "\n",
    "Set your binary target variable name. The helper will try to guess likely targets based on common names. \n",
    "If not found, set it manually. Also configure positive class if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b752b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to guess a binary target column\n",
    "candidate_targets = [\n",
    "    'label','target','outcome','progression','disease','ckd','aki','dn','event','y','class','has_ckd','has_aki'\n",
    "]\n",
    "\n",
    "target_col = None\n",
    "for c in candidate_targets:\n",
    "    if c in data.columns:\n",
    "        # check if binary-like\n",
    "        nunique = data[c].nunique(dropna=True)\n",
    "        if nunique <= 3:\n",
    "            target_col = c\n",
    "            break\n",
    "\n",
    "print(\"Guessed target  \", target_col)\n",
    "print(\"Value counts preview if target exists\")\n",
    "if target_col is not None:\n",
    "    print(data[target_col].value_counts(dropna=False).head())\n",
    "else:\n",
    "    print(\"No suitable target guessed. Please set target_col manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual override  set your target if needed\n",
    "# target_col = 'progression'  # Example\n",
    "\n",
    "if target_col is None:\n",
    "    raise ValueError(\"Please set target_col above to a binary column present in your dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f48244",
   "metadata": {},
   "source": [
    "## 3 Exploratory Data Analysis that Informs Modeling\n",
    "\n",
    "Keep this short and focused on insights that affect logistic regression. Use value counts for the target and check for missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "vc = data[target_col].value_counts(dropna=False)\n",
    "print(\"Target distribution\\n\", vc)\n",
    "\n",
    "# Basic missingness\n",
    "missing = data.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nTop 15 missingness\\n\", missing.head(15))\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "categorical_cols = [c for c in data.columns if c not in numeric_cols + [target_col]]\n",
    "\n",
    "print(\"\\nNumeric cols  \", len(numeric_cols))\n",
    "print(\"Categorical cols  \", len(categorical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5989ac6",
   "metadata": {},
   "source": [
    "## 4 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean target to 0 1\n",
    "y_raw = data[target_col]\n",
    "y = y_raw.copy()\n",
    "\n",
    "# If strings or yes no, convert to 0 1\n",
    "if y.dtype == 'O' or y.dtype.name == 'category':\n",
    "    y = y.astype(str).str.strip().str.lower().map({\n",
    "        '1':1,'true':1,'yes':1,'y':1,'positive':1,'pos':1,'disease':1,'progression':1\n",
    "    }).fillna(0).astype(int)\n",
    "elif set(np.unique(y)) - {0,1}:\n",
    "    # If numeric but not 0 1, convert by threshold at median\n",
    "    thresh = np.median(pd.to_numeric(y, errors='coerce').dropna())\n",
    "    y = (pd.to_numeric(y, errors='coerce') > thresh).astype(int)\n",
    "\n",
    "X = data.drop(columns=[target_col]).copy()\n",
    "\n",
    "# Simple impute strategy per type\n",
    "numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920147e",
   "metadata": {},
   "source": [
    "## 5 Scaling Comparison\n",
    "\n",
    "Compare StandardScaler, MinMaxScaler, and RobustScaler in a consistent evaluation setup. Use logistic regression with L2 penalty first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabad64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'standard': StandardScaler(),\n",
    "    'minmax': MinMaxScaler(),\n",
    "    'robust': RobustScaler()\n",
    "}\n",
    "\n",
    "results_scalers = []\n",
    "\n",
    "for name, scaler in scalers.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('pre', preprocess),\n",
    "        ('scale', scaler),\n",
    "        ('clf', LogisticRegression(max_iter=2000, penalty='l2', solver='lbfgs', random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc_ = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    results_scalers.append((name, acc, prec, rec, f1, auc_))\n",
    "\n",
    "pd.DataFrame(results_scalers, columns=['scaler','accuracy','precision','recall','f1','auc']).sort_values('auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83a93f",
   "metadata": {},
   "source": [
    "## 6 Hyperparameter Tuning\n",
    "\n",
    "Tune C and penalty. Use stratified CV. Note that L1 requires a solver that supports it. We will compare L1 and L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5542d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('pre', preprocess),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=3000, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {'clf__penalty': ['l2'], 'clf__solver': ['lbfgs','liblinear'], 'clf__C': [0.01, 0.1, 1, 10, 100]},\n",
    "    {'clf__penalty': ['l1'], 'clf__solver': ['liblinear','saga'], 'clf__C': [0.01, 0.1, 1, 10, 100]}\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=0)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params  \", grid.best_params_)\n",
    "print(\"Best CV AUC  \", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\nTest metrics\")\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision\", precision_score(y_test, y_pred, zero_division=0))\n",
    "print(\"Recall\", recall_score(y_test, y_pred, zero_division=0))\n",
    "print(\"F1\", f1_score(y_test, y_pred, zero_division=0))\n",
    "print(\"ROC AUC\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2cdaa",
   "metadata": {},
   "source": [
    "## 7 Diagnostic Plots\n",
    "\n",
    "ROC, PR curve, and confusion matrix. Add calibration to assess probability quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf77f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.title(\"ROC curve  best model\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "PrecisionRecallDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.title(\"Precision Recall curve  best model\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.title(\"Confusion Matrix  best model\")\n",
    "plt.show()\n",
    "\n",
    "# Calibration\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10, strategy='quantile')\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Observed frequency')\n",
    "plt.title('Calibration curve  best model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e768309",
   "metadata": {},
   "source": [
    "## 8 Threshold Tuning\n",
    "\n",
    "Use Youden J statistic to choose a threshold that balances sensitivity and specificity. Report updated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ec09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, y_proba)\n",
    "youden = tpr - fpr\n",
    "ix = np.argmax(youden)\n",
    "best_thr = thr[ix]\n",
    "best_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a34847",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_thr = (y_proba >= best_thr).astype(int)\n",
    "print(\"Threshold\", best_thr)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_pred_thr))\n",
    "print(\"Precision\", precision_score(y_test, y_pred_thr, zero_division=0))\n",
    "print(\"Recall\", recall_score(y_test, y_pred_thr, zero_division=0))\n",
    "print(\"F1\", f1_score(y_test, y_pred_thr, zero_division=0))\n",
    "print(\"ROC AUC\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126567e1",
   "metadata": {},
   "source": [
    "## 9 Interpretation\n",
    "\n",
    "Show feature coefficients for the best model. Map coefficients back to original column names after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82437b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names after preprocessing\n",
    "def get_feature_names(preprocessor, numeric_cols, categorical_cols):\n",
    "    num_features = numeric_cols\n",
    "    cat_features = categorical_cols\n",
    "    # For simplicity we assume no OneHot here  adjust if one hot is later added\n",
    "    return num_features + cat_features\n",
    "\n",
    "feature_names = get_feature_names(preprocess, numeric_cols, categorical_cols)\n",
    "\n",
    "clf = best_model.named_steps['clf']\n",
    "if hasattr(clf, 'coef_'):\n",
    "    coefs = pd.Series(clf.coef_.ravel(), index=feature_names)\n",
    "    coefs.sort_values(key=np.abs, ascending=False, inplace=True)\n",
    "    display(coefs.head(20))\n",
    "else:\n",
    "    print(\"No coefficients available on this classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb4332",
   "metadata": {},
   "source": [
    "## 10 Overfitting Control\n",
    "\n",
    "Briefly discuss what you did to reduce overfitting. Mention CV, regularization, data split, and threshold tuning results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce7533",
   "metadata": {},
   "source": [
    "## 11 Yellowdig Source Snippet\n",
    "\n",
    "Paste the following in Yellowdig with your own short note on quality.\n",
    "\n",
    "**Citation suggestion APA**  \n",
    "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, É. (2011). Scikit learn  Machine Learning in Python. *Journal of Machine Learning Research, 12*, 2825 2830.\n",
    "\n",
    "**Why high quality**  \n",
    "Peer reviewed venue and foundational library paper. Clear methods and implementation details. Widely cited in machine learning research and practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751e0d9",
   "metadata": {},
   "source": [
    "## 12 Appendix Notes for Milestone One\n",
    "\n",
    "Flag figures and sections you plan to reuse in the 8 to 10 page summary. Mention which parts map to breadth and which week you plan to go deep on for depth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
